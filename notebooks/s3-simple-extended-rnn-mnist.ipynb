{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from utils import logging as lg\n",
    "\n",
    "lg.set_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 06:26:22,846 | INFO : plot.py(setup 14) - Setup plot parameters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from utils import data_provider\n",
    "from utils import experiment_artifact\n",
    "from notebook_utils import plot\n",
    "plot.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-10 14:18:31,132 | INFO : data_provider.py(get_mnist 17) - Load MNIST : train\n",
      "2017-10-10 14:18:31,540 | INFO : data_provider.py(get_mnist 17) - Load MNIST : test\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = data_provider.get_mnist('train', dir_path='../data/mnist')\n",
    "X_test, Y_test = data_provider.get_mnist('test', dir_path='../data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2d = np.copy(X_train.reshape((-1,28,28)))\n",
    "X_test_2d = np.copy(X_test.reshape((-1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-10 14:18:32,321 | INFO : plot.py(show_and_save 21) - save fig to ../figures/nb_figures/mnist-label5-with-cols.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAADJCAYAAAA5I4+DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNKIAAAAAgKT+H+wMIf2nS3/vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14d670f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mnist_with_columns(data_idx, col_indices):\n",
    "    plt.figure(figsize=(16,3))\n",
    "\n",
    "    plt.subplot(1,5,1)\n",
    "\n",
    "    plt.imshow(X_train[data_idx,:].reshape((28,28)))\n",
    "    plt.title('Data Label %d' % int(np.sum(np.arange(10) * Y_train[data_idx,:])))\n",
    "\n",
    "    count = 2\n",
    "    for col_idx in col_indices:\n",
    "        plt.subplot(1,5,count)\n",
    "        img_zero = np.zeros((28,28))\n",
    "        img_zero[:, col_idx] = X_train_2d[data_idx, :, col_idx]\n",
    "        plt.title('Col %d-th' % col_idx)\n",
    "        plt.imshow(img_zero, vmin=0, vmax=255)\n",
    "        count = count + 1\n",
    "plot_mnist_with_columns(data_idx = 0, col_indices = [5, 10,15,20])\n",
    "plt.show_and_save(title='mnist-label5-with-cols.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x, y, n=1):\n",
    "    l = len(x)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield (x[ndx:min(ndx + n, l)],  y[ndx:min(ndx + n, l)])\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, dims, name, stddev=0.1):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(dims, stddev=stddev),\n",
    "            name=\"%s_weights\"%name\n",
    "        )\n",
    "\n",
    "        bias = tf.Variable(\n",
    "            tf.zeros(dims[1]),\n",
    "            name=\"%s_bias\"%name\n",
    "        )\n",
    "        \n",
    "        self.W = weights\n",
    "        self.b = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "![image.png](https://i.imgur.com/LjLKm7S.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Notations\n",
    "- $\\boldsymbol{x}^{(\\alpha)}_{(\\cdot,tk:(t+1)k-1)}$  : sample $\\alpha$ with all rows of columns $tk$ to $(t+1)k-1$ and reshaped to a column vector\n",
    "    - $k \\in \\{1,4,7,14,28\\}$\n",
    "    - $t = \\{1, \\dots, \\frac{28}{k} \\}$\n",
    "- $\\boldsymbol{W}_{in}$, $\\boldsymbol{b}_{in}$ : weights and bias of input representation layer $\\boldsymbol{I}^{(\\alpha)}_t$\n",
    "$$\n",
    "\\boldsymbol{I}^{(\\alpha)}_t = \\text{RELU} \\bigg( \\boldsymbol{x}^{(\\alpha)}_{(\\cdot,tk:(t+1)k-1)} \\boldsymbol{W}_{in} + \\boldsymbol{b}_{in}  \\bigg)\n",
    "$$\n",
    "- $\\boldsymbol{r}^{(\\alpha)}_{t}$ : recurrent inputs of column $t$ of sample $\\alpha$\n",
    "- $\\widetilde{\\boldsymbol{I}}^{(\\alpha)}_{t}$ : concatenation of $\\boldsymbol{I}^{(\\alpha)}_{t}$  and $\\boldsymbol{r}_{t}$\n",
    "- $\\boldsymbol{W}_{h}$, $\\boldsymbol{b}_{h}$ : weights and bias of cell hidden layer $\\boldsymbol{H}^{(\\alpha)}_t$\n",
    "$$\n",
    "\\boldsymbol{H}^{(\\alpha)}_t = \\text{RELU} \\bigg( \\widetilde{\\boldsymbol{I}}^{(\\alpha)}_{t} \\boldsymbol{W}_{h} + \\boldsymbol{b}_{h}  \\bigg)\n",
    "$$\n",
    "- $\\boldsymbol{W}_{r}$, $\\boldsymbol{b}_{r}$ : weights and bias for recurrent unit activations $\\boldsymbol{r}^{(\\alpha)}_{t+1}$\n",
    "$$\n",
    "\\boldsymbol{r}^{(\\alpha)}_{t+1} = \\text{RELU} \\bigg( \\boldsymbol{H}^{(\\alpha)}_t \\boldsymbol{W}_{r} + \\boldsymbol{b}_{r}  \\bigg)\n",
    "$$\n",
    "- $\\boldsymbol{W}_{o1}$, $\\boldsymbol{b}_{o1}$ : weights and bias of 1st output layer $\\boldsymbol{O}^{(\\alpha)}_t$\n",
    "$$\n",
    "\\boldsymbol{O}^{(\\alpha)}_t = \\text{RELU} \\bigg( \\boldsymbol{H}^{(\\alpha)}_t \\boldsymbol{W}_{o1} + \\boldsymbol{b}_{o1}  \\bigg)\n",
    "$$\n",
    "- $\\boldsymbol{W}_{o2}$, $\\boldsymbol{b}_{o2}$ : weights and bias of 2nd output layer $\\hat{\\boldsymbol{O}}^{(\\alpha)}_t$\n",
    "$$\n",
    "\\hat{\\boldsymbol{O}}^{(\\alpha)}_t = \\text{RELU} \\bigg( \\boldsymbol{O}^{(\\alpha)}_t \\boldsymbol{W}_{o2} + \\boldsymbol{b}_{o2}  \\bigg)\n",
    "$$\n",
    "- $\\hat{\\boldsymbol{y}}^{(\\alpha)}$ : class predictions of $\\boldsymbol{x}^{(\\alpha)}$\n",
    "$$\n",
    "\\hat{\\boldsymbol{y}}^{(\\alpha)} = \\text{SOFTMAX} \\bigg( \\hat{\\boldsymbol{O}}^{(\\alpha)}_{\\text{max}(t)}  \\bigg) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters are choosed arbitrarily.\n",
    "NETWORK_PARAMS = {\n",
    "    'input_max_seq_length': 28,\n",
    "    'input_dims': 28,\n",
    "    \n",
    "    'learning_rate': 0.005,\n",
    "    'batch_size': 100,\n",
    "    \n",
    "    'pior_cell_layer_units': 100,\n",
    "    'hidden_units': 60,\n",
    "    'pior_output_units': 50,\n",
    "    'output_units': 10,\n",
    "    'recurrent_units': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-10 15:00:21,272 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 3) - Training 2 columns at a time\n",
      "2017-10-10 15:00:27,209 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 1\n",
      "2017-10-10 15:00:27,340 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 1 : train acc 0.180000, loss 2.296820\n",
      "2017-10-10 15:00:27,354 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 2 : train acc 0.200000, loss 2.295113\n",
      "2017-10-10 15:00:27,367 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 3 : train acc 0.190000, loss 2.288708\n",
      "2017-10-10 15:00:27,382 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 4 : train acc 0.160000, loss 2.277057\n",
      "2017-10-10 15:00:27,397 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 5 : train acc 0.160000, loss 2.272106\n",
      "2017-10-10 15:00:27,415 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 6 : train acc 0.140000, loss 2.262749\n",
      "2017-10-10 15:00:27,432 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 7 : train acc 0.180000, loss 2.231560\n",
      "2017-10-10 15:00:27,447 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 8 : train acc 0.150000, loss 2.193649\n",
      "2017-10-10 15:00:27,467 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 9 : train acc 0.190000, loss 2.168370\n",
      "2017-10-10 15:00:31,817 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 2\n",
      "2017-10-10 15:00:34,695 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 1000 : train acc 0.860000, loss 0.371007\n",
      "2017-10-10 15:00:36,080 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 3\n",
      "2017-10-10 15:00:40,206 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 4\n",
      "2017-10-10 15:00:41,627 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 2000 : train acc 0.900000, loss 0.277285\n",
      "2017-10-10 15:00:44,401 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 5\n",
      "2017-10-10 15:00:48,504 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 3000 : train acc 0.950000, loss 0.249475\n",
      "2017-10-10 15:00:48,505 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 6\n",
      "2017-10-10 15:00:52,610 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 7\n",
      "2017-10-10 15:00:55,372 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 4000 : train acc 0.950000, loss 0.184316\n",
      "2017-10-10 15:00:56,771 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 8\n",
      "2017-10-10 15:01:00,887 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 9\n",
      "2017-10-10 15:01:02,286 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 5000 : train acc 0.940000, loss 0.150532\n",
      "2017-10-10 15:01:05,031 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 51) - epoch 10\n",
      "2017-10-10 15:01:09,751 | INFO : <ipython-input-40-210fb1765345>(train_and_evaluate 60) - step 6000 : train acc 0.960000, loss 0.235883\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>column_at_a_time</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>epoch</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hidden_units</td>\n",
       "      <td>60.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input_dims</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input_max_seq_length</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>output_units</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pior_cell_layer_units</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pior_output_units</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recurrent_units</td>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seq_length</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                attribute     value\n",
       "12               accuracy    0.9227\n",
       "10             batch_size  100.0000\n",
       "5        column_at_a_time    2.0000\n",
       "11                  epoch   10.0000\n",
       "9            hidden_units   60.0000\n",
       "1              input_dims   28.0000\n",
       "2    input_max_seq_length   28.0000\n",
       "4           learning_rate    0.0050\n",
       "8            output_units   10.0000\n",
       "6   pior_cell_layer_units  100.0000\n",
       "3       pior_output_units   50.0000\n",
       "0         recurrent_units   20.0000\n",
       "7              seq_length   14.0000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_evaluate(seq_length=1, epoch=2, _lr=NETWORK_PARAMS['learning_rate'], debug=False):\n",
    "    no_input_cols = NETWORK_PARAMS['input_max_seq_length'] // seq_length\n",
    "    logging.info('Training %d columns at a time' % no_input_cols)\n",
    "\n",
    "    recurrent_inputs = tf.placeholder(tf.float32, shape=(None, NETWORK_PARAMS['recurrent_units']))\n",
    "\n",
    "\n",
    "    ly_input_1   = Layer((NETWORK_PARAMS['input_dims']*no_input_cols, NETWORK_PARAMS['pior_cell_layer_units']), 'input')\n",
    "    ly_input_2   = Layer((NETWORK_PARAMS['pior_cell_layer_units'] +NETWORK_PARAMS['recurrent_units'] , NETWORK_PARAMS['hidden_units']), 'input_tc')\n",
    "    \n",
    "    ly_output_1  = Layer((NETWORK_PARAMS['hidden_units'], NETWORK_PARAMS['pior_output_units']), 'pior_output')\n",
    "    ly_output_2  = Layer((NETWORK_PARAMS['pior_output_units'], NETWORK_PARAMS['output_units']), 'output')\n",
    "    \n",
    "    ly_recurrent = Layer((NETWORK_PARAMS['hidden_units'], NETWORK_PARAMS['recurrent_units']), 'recurrent')\n",
    "\n",
    "\n",
    "    x_input = tf.placeholder(tf.float32, shape=(None, NETWORK_PARAMS['input_dims'], NETWORK_PARAMS['input_dims']))\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    rr = recurrent_inputs\n",
    "    \n",
    "\n",
    "    for i in range(0, x_input.shape[1], no_input_cols):\n",
    "        ii = tf.reshape(x_input[:,i:i+no_input_cols], [-1, no_input_cols * NETWORK_PARAMS['input_dims'] ])\n",
    "        itc = tf.nn.relu(tf.matmul(ii, ly_input_1.W) + ly_input_1.b)\n",
    "        \n",
    "        xr = tf.concat([itc, rr], axis=1)\n",
    "        ha = tf.nn.relu(tf.matmul(xr, ly_input_2.W) + ly_input_2.b)\n",
    "\n",
    "        rr = tf.nn.relu(tf.matmul(ha, ly_recurrent.W) + ly_recurrent.b)\n",
    "        \n",
    "        ho = tf.nn.relu(tf.matmul(ha, ly_output_1.W) + ly_output_1.b)\n",
    "        ot = tf.matmul(ho, ly_output_2.W) + ly_output_2.b\n",
    "        \n",
    "    y = ot\n",
    "\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=_lr).minimize(loss_op)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        step = 1\n",
    "        for i in range(epoch):\n",
    "            logging.info('epoch %d' % (i+1))\n",
    "            for xf, yf in batch_data(X_train_2d, Y_train, n=NETWORK_PARAMS['batch_size']):\n",
    "        \n",
    "                rr = np.zeros((NETWORK_PARAMS['batch_size'], NETWORK_PARAMS['recurrent_units']))\n",
    "                sess.run(train_op, feed_dict={x_input: xf, y_: yf, recurrent_inputs: rr})\n",
    "                \n",
    "                if (step % 1000 == 0 or step < 10) and debug:\n",
    "                    rr = np.zeros((len(yf), NETWORK_PARAMS['recurrent_units']))\n",
    "                    acc, loss = sess.run([accuracy, loss_op], feed_dict={x_input: xf, y_: yf, recurrent_inputs:rr})\n",
    "                    logging.info('step %d : train acc %f, loss %f' % (step, acc, loss))\n",
    "                    \n",
    "                step = step + 1\n",
    "                \n",
    "        rr = np.zeros((len(Y_test), NETWORK_PARAMS['recurrent_units']))\n",
    "        acc = sess.run(accuracy, feed_dict={x_input: X_test_2d, y_: Y_test, recurrent_inputs: rr})\n",
    "        \n",
    "        res = dict(\n",
    "            seq_length = seq_length,\n",
    "            epoch = epoch,\n",
    "            column_at_a_time = no_input_cols,\n",
    "            accuracy = acc,\n",
    "            **NETWORK_PARAMS\n",
    "        )\n",
    "        \n",
    "        return res\n",
    "    \n",
    "res = train_and_evaluate(seq_length=14, epoch=10)\n",
    "\n",
    "plot.tabularize_params(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "Command for running experiments\n",
    "\n",
    "```\n",
    "$ python scripts/train.py s3-network --seq-length 7 --epoch 50 --lr 0.005 --batch 100 \\\n",
    "--architecture-str 'in1:100|hidden:60|out1:30|out2:10--recur:7' --verbose --result_dir ./experiment-results/sprint-2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = experiment_artifact.get_results('../experiment-results/sprint-2').sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>architecture_name</th>\n",
       "      <th>column_at_a_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>layer_hidden</th>\n",
       "      <th>layer_in1</th>\n",
       "      <th>layer_out1</th>\n",
       "      <th>layer_out2</th>\n",
       "      <th>layer_recur</th>\n",
       "      <th>lr</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9722</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-10--23-47</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.9716</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-11--00-28</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9712</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-10--23-56</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9711</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-11--00-04</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9705</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-10--22-59</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy architecture_name  column_at_a_time  epoch  \\\n",
       "12    0.9722        s3_network                 4     50   \n",
       "39    0.9716        s3_network                 4     50   \n",
       "17    0.9712        s3_network                 4     50   \n",
       "22    0.9711        s3_network                 4     50   \n",
       "2     0.9705        s3_network                 4     50   \n",
       "\n",
       "          experiment_name  layer_hidden  layer_in1  layer_out1  layer_out2  \\\n",
       "12  rnn-2017-10-10--23-47            60        100          30          10   \n",
       "39  rnn-2017-10-11--00-28            60         80          50          10   \n",
       "17  rnn-2017-10-10--23-56            60        100          50          10   \n",
       "22  rnn-2017-10-11--00-04            60        100          30          10   \n",
       "2   rnn-2017-10-10--22-59            60        100          50          10   \n",
       "\n",
       "    layer_recur  lr  seq_length  \n",
       "12            7 NaN           7  \n",
       "39           10 NaN           7  \n",
       "17           10 NaN           7  \n",
       "22           10 NaN           7  \n",
       "2             7 NaN           7  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 columns at a time\n",
    "df_results[df_results.seq_length==7][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>architecture_name</th>\n",
       "      <th>column_at_a_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>layer_hidden</th>\n",
       "      <th>layer_in1</th>\n",
       "      <th>layer_out1</th>\n",
       "      <th>layer_out2</th>\n",
       "      <th>layer_recur</th>\n",
       "      <th>lr</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.9473</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>rnn-2017-10-11--14-44</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.9451</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-11--15-02</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.9417</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>rnn-2017-10-11--15-29</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.9394</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>rnn-2017-10-11--14-36</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.9388</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>rnn-2017-10-11--15-15</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy architecture_name  column_at_a_time  epoch  \\\n",
       "60    0.9473        s3_network                 2     10   \n",
       "69    0.9451        s3_network                 2     50   \n",
       "84    0.9417        s3_network                 2     20   \n",
       "57    0.9394        s3_network                 2     20   \n",
       "76    0.9388        s3_network                 2     10   \n",
       "\n",
       "          experiment_name  layer_hidden  layer_in1  layer_out1  layer_out2  \\\n",
       "60  rnn-2017-10-11--14-44            60         50          30          10   \n",
       "69  rnn-2017-10-11--15-02            60         30          50          10   \n",
       "84  rnn-2017-10-11--15-29            60         30          30          10   \n",
       "57  rnn-2017-10-11--14-36            60         50          50          10   \n",
       "76  rnn-2017-10-11--15-15            60         30          50          10   \n",
       "\n",
       "    layer_recur  lr  seq_length  \n",
       "60           20 NaN          14  \n",
       "69            7 NaN          14  \n",
       "84           20 NaN          14  \n",
       "57           20 NaN          14  \n",
       "76           20 NaN          14  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 columns at a time\n",
    "df_results[df_results.seq_length==14][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>architecture_name</th>\n",
       "      <th>column_at_a_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>layer_hidden</th>\n",
       "      <th>layer_in1</th>\n",
       "      <th>layer_out1</th>\n",
       "      <th>layer_out2</th>\n",
       "      <th>layer_recur</th>\n",
       "      <th>lr</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.8769</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>rnn-2017-10-11--15-42</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.8212</td>\n",
       "      <td>s3_network</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>rnn-2017-10-11--15-39</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.7539</td>\n",
       "      <td>s2_network</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>rnn-2017-10-11--16-59</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.7386</td>\n",
       "      <td>s2_network</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>rnn-2017-10-11--17-50</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.005</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.7205</td>\n",
       "      <td>s2_network</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>rnn-2017-10-11--17-43</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.005</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy architecture_name  column_at_a_time  epoch  \\\n",
       "90     0.8769        s3_network                 1     20   \n",
       "88     0.8212        s3_network                 1     10   \n",
       "114    0.7539        s2_network                 1     20   \n",
       "130    0.7386        s2_network                 1     10   \n",
       "128    0.7205        s2_network                 1     50   \n",
       "\n",
       "           experiment_name  layer_hidden  layer_in1  layer_out1  layer_out2  \\\n",
       "90   rnn-2017-10-11--15-42            60         20          50          10   \n",
       "88   rnn-2017-10-11--15-39            60         20          50          10   \n",
       "114  rnn-2017-10-11--16-59            60         10          50          10   \n",
       "130  rnn-2017-10-11--17-50            60         10          30          10   \n",
       "128  rnn-2017-10-11--17-43            60         10          50          10   \n",
       "\n",
       "     layer_recur     lr  seq_length  \n",
       "90            20  0.005          28  \n",
       "88            20  0.005          28  \n",
       "114           20  0.005          28  \n",
       "130           40  0.005          28  \n",
       "128           40  0.005          28  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 col at a time\n",
    "df_results[df_results.seq_length==28][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"../data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_layer(dims,name):\n",
    "#     weights = tf.Variable(\n",
    "#         tf.truncated_normal(dims, stddev=0.1),\n",
    "#         name=\"%s_weights\"%name\n",
    "#     )\n",
    "\n",
    "#     bias = tf.Variable(\n",
    "#         tf.zeros(dims[1]),\n",
    "#         name=\"%s_bias\"%name\n",
    "#     )\n",
    "#     return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simple_relu_net():\n",
    "#     learning_rate=0.1\n",
    "#     x_input = tf.placeholder(tf.float32, shape=(None, NETWORK_PARAMS['input_dims']*NETWORK_PARAMS['input_dims']))\n",
    "#     y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#     l1_w, l1_b = build_layer((784,256), 'l1')\n",
    "#     lx_w, lx_b = build_layer((256,256), 'lx')\n",
    "#     l2_w, l2_b = build_layer((256,10), 'l2')\n",
    "    \n",
    "#     mt = tf.nn.relu(tf.matmul(x_input, l1_w) + l1_b )\n",
    "#     gg = tf.nn.relu(tf.matmul(mt, lx_w) + lx_b )\n",
    "#     ot = tf.matmul(gg, l2_w) + l2_b\n",
    "     \n",
    "#     y = ot\n",
    "\n",
    "#     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "#     optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#     train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "#         correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#         for i in range(500):\n",
    "#             batch = mnist.train.next_batch(128)\n",
    "            \n",
    "#             sess.run(train_op, feed_dict={x_input: batch[0], y_: batch[1]})\n",
    "            \n",
    "#             if i % 100 == 0 or i == 1:\n",
    "                \n",
    "#                 acc, loss = sess.run([accuracy, loss_op], feed_dict={x_input: batch[0], y_: batch[1]})\n",
    "#                 print('Loss %f, training acc %f)' %(loss, acc))\n",
    "# #                 print(\"Train Accuracy : %.4f\" % sess.run(accuracy, feed_dict={x_input: X_train_2d.reshape(-1,28*28), y_: Y_train}))\n",
    "# #                 print(\"Train Accuracy : %.4f\" % sess.run(accuracy, feed_dict={x_input: mnist.train.images, y_: mnist.train.labels}))\n",
    "#         print('Test acc %f' % sess.run(accuracy, feed_dict={x_input: mnist.test.images, y_: mnist.test.labels}))\n",
    "# simple_relu_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-10-10--22-12'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y-%m-%d--%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 Thesis Kernel",
   "language": "python",
   "name": "py3-thesis-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "670px",
    "left": "0px",
    "right": "20px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
